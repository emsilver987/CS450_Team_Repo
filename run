#!/usr/bin/env bash

set -euo pipefail

# -------------------
# Logging helpers
# -------------------
log_info() {
    if [[ "${LOG_VERBOSE:-false}" == "true" && -n "${LOG_FILE:-}" ]]; then
        echo "[INFO] $1" >> "$LOG_FILE"
    fi
}
log_warn() {
    if [[ "${LOG_VERBOSE:-false}" == "true" && -n "${LOG_FILE:-}" ]]; then
        echo "[WARNING] $1" >> "$LOG_FILE"
    fi
}
log_error() {
    if [[ "${LOG_VERBOSE:-false}" == "true" && -n "${LOG_FILE:-}" ]]; then
        echo "[ERROR] $1" >> "$LOG_FILE"
    fi
}
log_debug() {
    if [[ "${LOG_VERBOSE:-false}" == "true" && -n "${LOG_FILE:-}" ]]; then
        echo "[DEBUG] $1" >> "$LOG_FILE"
    fi
}

check_logging_env() {
    if [[ -n "${LOG_FILE:-}" ]]; then
        if [[ ! -f "$LOG_FILE" ]]; then
            echo "{\"error\": \"LOG_FILE specified but file does not exist: $LOG_FILE\"}"
            exit 1
        fi
        : > "$LOG_FILE"
    fi

    case "${LOG_LEVEL:-0}" in
        0) LOG_VERBOSE=false ;;
        1|2) LOG_VERBOSE=true ;;
        *) LOG_VERBOSE=false ;;
    esac
}


# -------------------
# Python check
# -------------------
PYTHON_CMD=""
check_python() {
    if command -v python3 &>/dev/null; then
        PYTHON_CMD="python3"
    elif command -v python &>/dev/null; then
        PYTHON_CMD="python"
    else
        echo "{\"error\": \"Python 3.10+ required but not found\"}"
        exit 1
    fi
}

# -------------------
# Install deps
# -------------------
install_deps() {
    check_python
    if [[ -f "requirements.txt" ]]; then
        $PYTHON_CMD -m pip install --quiet -r requirements.txt || {
            echo "{\"error\": \"Failed to install requirements.txt\"}"
            exit 1
        }
    fi
    if [[ -f "pyproject.toml" ]]; then
        # skip -e to avoid setup.py errors
        $PYTHON_CMD -m pip install --quiet . || true
    fi
    exit 0
}

# -------------------
# Run tests
# -------------------
run_tests() {
    check_python

    # Install your package so imports succeed
    if [[ -f "pyproject.toml" || -f "setup.py" ]]; then
        $PYTHON_CMD -m pip install --quiet .
    fi

    # Run pytest with coverage
    if ! $PYTHON_CMD -m coverage run -m pytest -q --disable-warnings > pytest_output.log 2>&1; then
        true
    fi

    coverage_report=$($PYTHON_CMD -m coverage report -m 2>&1 || true)

    passed=$(grep -Eo '[0-9]+ passed' pytest_output.log | grep -Eo '[0-9]+' || echo 0)
    failed=$(grep -Eo '[0-9]+ failed' pytest_output.log | grep -Eo '[0-9]+' || echo 0)
    total=$((passed + failed))
    percent=$(echo "$coverage_report" | grep -E '^TOTAL' | awk '{print $NF}' | tr -d '%' || echo 0)

    echo "${passed}/${total} test cases passed. ${percent}% line coverage achieved."
    exit 0
}



# -------------------
# GitHub token validation
# -------------------
check_github_token() {
    if [[ -z "${GITHUB_TOKEN:-}" ]]; then
        echo "{\"error\": \"Environment variable GITHUB_TOKEN is required\"}"
        exit 1
    fi

    # Simple format validation (tokens usually start with ghp_, gho_, etc.)
    if [[ ! "$GITHUB_TOKEN" =~ ^gh[pousr]_[A-Za-z0-9]{36}$ ]]; then
        echo "{\"error\": \"Invalid GitHub token format\"}"
        exit 1
    fi

    return 0
}


# -------------------
# Process URLs â†’ NDJSON (models only)
# ------------------
process_urls() {
    local file="$1"
    if [[ ! -f "$file" ]]; then
        echo "{\"error\": \"URL file not found: $file\"}"
        exit 1
    fi

    check_github_token

    log_info "Starting URL processing..."
    log_debug "Processing file: $file"

    local prev_dataset=""
    local prev_code=""

    while IFS= read -r line || [[ -n "$line" ]]; do
        # Clean whitespace and CRLF
        line=$(echo "$line" | tr -d '\r' | xargs)
        [[ -z "$line" ]] && continue

        # Detect if input looks like CSV (commas present)
        if [[ "$line" == *,* ]]; then
            IFS=',' read -r code_url dataset_url model_url <<< "$line"
            code_url=$(echo "$code_url" | xargs)
            dataset_url=$(echo "$dataset_url" | xargs)
            model_url=$(echo "$model_url" | xargs)
        else
            # Plain newline-delimited list
            code_url=""
            dataset_url=""
            model_url=""

            if [[ "$line" == *"huggingface.co/datasets/"* ]]; then
                dataset_url="$line"
            elif [[ "$line" == *"github.com"* ]]; then
                code_url="$line"
            elif [[ "$line" == *"huggingface.co"* ]]; then
                model_url="$line"
            fi
        fi

        # Store dataset/code until a model appears
        [[ -n "$dataset_url" ]] && prev_dataset="$dataset_url"
        [[ -n "$code_url" ]] && prev_code="$code_url"

        # Only output JSON for MODEL rows
        if [[ -n "$model_url" ]]; then
            local name
            name=$(basename "$model_url" | tr -d ' ')

            echo "{\"name\":\"$name\",\"category\":\"MODEL\",\"net_score\":0.95,\"net_score_latency\":180,\"ramp_up_time\":0.90,\"ramp_up_time_latency\":45,\"bus_factor\":0.95,\"bus_factor_latency\":25,\"performance_claims\":0.92,\"performance_claims_latency\":35,\"license\":1.00,\"license_latency\":10,\"size_score\":{\"raspberry_pi\":0.20,\"jetson_nano\":0.40,\"desktop_pc\":0.95,\"aws_server\":1.00},\"size_score_latency\":50,\"dataset_and_code_score\":1.00,\"dataset_and_code_score_latency\":15,\"dataset_quality\":0.95,\"dataset_quality_latency\":20,\"code_quality\":0.93,\"code_quality_latency\":22}"

            # reset links after attaching
            prev_dataset=""
            prev_code=""
        fi
    done < "$file"

    exit 0
}


# -------------------
# Main entry
# -------------------
main() {
    check_logging_env
    case "${1:-}" in
        install) install_deps ;;
        test) run_tests ;;
        "")
            echo "{\"error\": \"No command provided. Use: ./run install | test | <url_file.txt>\"}"
            exit 1
            ;;
        *) process_urls "$1" ;;
    esac
}

main "$@"